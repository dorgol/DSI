## 0. Overview 

There are many packages in R for network analysis.

Packages grew up around modeling/analysis frameworks with core authors.

Tutorial is organized by package + case study + exercise.

Covers major packages, biased to my experience.

Analysis packages:

- statnet (ergm & tergm, hergm, xergm, Epimodel)
- igraph
- latentnet

Visualization packages:

- networkDynamic
- visNetwork
- gg*

## A) Setup 
```{r setup, cache = T, warning = F, message = F}

# listing major packages once here so you can make sure they're installed
library(dplyr)
library(statnet)
library(lubridate)
library(igraph)
# Most are listed again where first used

# Working directory - upate for your system
wd = "~/Documents/DSI/network_analysis_in_R/"
```

## B) Some terminology (more to come)

- Network or Graph
- Nodes (or Vertices), Edges
- *Binary* networks (0,1 edges)
- *Valued* networks or *signed* networks
- *Directed* (i->j is not the same edge as j->i)
    + transportation, one-way streets
- *Undirected*
    + friendships
- Dyad is set of two nodes and a single edge if undirected, two edges if directed
- *Bipartite*
    + heterosexual sexual relationships
- Adjacency matrix - Matrix representation of a network. N x N.
    + Symmetric if network is undirected
- Edge list - List representation; start and end of all edges.
    + Efficient if network is sparse


------------------------------------------------------------------------------------------

## 1. Statnet 

A family of packages for all stages of network analysis based in exponential random graph models (ERGM).

`statnet` (version 2018.10): Depends:	`R` (≥ 3.0), `tergm` (≥ 3.5.2), `ergm.count` (≥ 3.3), `sna` (≥ 2.4), `tsna` (≥ 0.2)
Imports:	`ergm` (≥ 3.9.4), `network` (≥ 1.13), `networkDynamic` (≥ 0.9), `statnet.common` (≥ 4.1.4)

Authors Handcock, Hunter, Butts, Goodreau, Krivitsky, Bender-deMoll, Morris, M.
Roots in social networks, sociology, epidemiology

**Exponential Random Graph Model**

$$P(Y) = \frac{\exp({b_1t_1+b_2t_2+...+b_pt_p})}{C(X,N)}$$

- Describes the probability of a network Y
    + $t$ is a vector of statistics about the network which may depend on $Y$ and attributes of the nodes or edges contained in $X$.
    + $t$ may include the number of edges, number of isolates, number of edges matching on a certain covariate, etc. 
    + $b$ is a vector of coefficients that determine the impact (direction and magnitude) of the statistics
- Maximum entropy distribution on graph space
- Simple to express, may be hard to implement

- SO many graphs -> C is intractible $O(2^{n^2})$ for binary networks
- MPLE or MCMC-MLE for inference. Explore the parameter space and find optimal values.
- DEGENERACY

ERGM are generally best-suited for smaller networks with interesting attributes that we want to explore in relation to the network structure.

## Example: Supreme Court Decisions about First Amendment

Providers of this data interested in :

- Patterns of homophily, especially if the justice characteristics are associated with justices deciding in the similar way, e.g. 
    + gender
    + age
    + religion

We'll want to control for characteristics like party of appointing president. 

Data starts in 1994 because that is the first year with more than one female Supreme Court justice.

<center>![RBG](/Users/janecarlen/Documents/DSI/network_analysis_in_R/rbg.jpg)</center>

## A) Convert raw data to a network object 

Common that our data starts as one or more csv files. Edges and node attributes may be seperate.
We need to convert this to network data.

#### Load and inspect data

We will discover that this is a bipartite network.

The data includes detailed opinion information which is captured by the "Target" number and "Opinion.information" variable. At least for visualization let's condense this slightly to just the Main, Concurrence, Dissent etc. labels contained in the "Type" variable. We will do this by grouping the Target by Type.

```{r supreme_court_load, echo = T, cache = T, warning = F, message = F}

sc.edges = read.csv(paste(wd, "GSoCversionOpinions-EDGES.csv", sep = "") )
sc.nodes = read.csv(paste(wd, "GSoCversionOpinions-NODES.csv", sep = ""))
summary(sc.edges)
summary(sc.nodes)

#list unique case names and dates
caseinfo = sc.edges %>% group_by(Case.name) %>% summarize(date = first(Case.date))
head(caseinfo, 10)

#list unique decisions names and dates
sc.edges.condensed = sc.edges %>% group_by(Source, Case.name, Type) %>% summarize(year = first(Case.date))
sc.edges.condensed$ID = sc.edges.condensed %>% group_by(Case.name, Type) %>% group_indices()
head(sc.edges.condensed, 10)
```

#### Convert to network data using `statnet`

How do we create a unimodal network from a bipartite one?

```{r supreme_court_network_bipartite, echo = T, cache = T, warning = F, message = F}

library(statnet) # loads statnet, tsna, sna, ergm.count, statnet.common, tergm, networkDynamic, ergm, network

n.judges = 14
n.decisions = max(sc.edges.condensed$ID)

sc.bipartite = network(sc.edges.condensed[,c("Source", "ID")], bipartite = n.judges,
                       vertex.attr = list(vertex.type = c(rep(2,n.judges), rep(1, n.decisions)), 
                                          year = c(rep(2,n.judges), gray(1 - (sc.edges.condensed$year - 1994)/23)),
                                          name = c(rep(2,n.judges), sc.edges.condensed$Case.name),
                                          label = c(as.character(sc.nodes$Label), rep("", n.decisions)),
                                          decision.type = c(rep(1,n.judges), as.numeric(sc.edges.condensed$Type))))

#dev.new()
plot(sc.bipartite,
     vertex.sides = 2+(as.numeric(sc.bipartite%v%"vertex.type"))^4,
     vertex.cex = sc.bipartite%v%"vertex.type", 
     vertex.col = sc.bipartite%v%"decision.type", #sc.bipartite%v%"year",
     label = sc.bipartite%v%"label",
     main = "Bipartite Network of 1st Amendment Supreme Court Decisions 1994-2017", edge.col = "gray",
     label.col = 4, label.cex = 1.2, label.pos = 3)

legend("topleft", legend = c("Judge", "Decision"), col = 1, pch = c(19,2), cex = 1.2)
legend("bottomleft", legend = levels(sc.edges.condensed$Type)[-1], col = 2:5, pch = 17)
```

#### Convert to unimodal network

<center>![genius?](/Users/janecarlen/Documents/DSI/network_analysis_in_R/goodwill_question.jpg)</center>

```{r supreme_court_network_unimode, echo = T, cache = T, warning = F, message = F}

library(lubridate)

sc.projection = (as.sociomatrix(sc.bipartite) %*% t(as.sociomatrix(sc.bipartite)))[1:n.judges,1:n.judges]

# slight discrepancy between appearance of judges in edgelist and this projection due to=
# duplicate edges being listed when a decision was split in two (e.g. "part" and "rest")

sc.nodes$birthyear = year(as.Date(as.character(sc.nodes$Date.of.birth), format = "%m/%d/%Y"))

sc.attr.list = list(label = c(as.character(sc.nodes$Label)),
                          appointed = as.numeric(sc.nodes$Appointing.President[1:n.judges]),
                          appearances = diag(sc.projection),
                          religion = as.character(sc.nodes$Religion..broad.[1:n.judges]),
                          gender = as.character(sc.nodes$Gender[1:n.judges]),
                          role = as.character(sc.nodes$Role[1:n.judges]))

sc.unimode = network(sc.projection, directed = F, names.eval = "codecisions", ignore.eval = F,
                        vertex.attr = sc.attr.list)
                     

religion.pch = 2 + as.numeric(as.factor(sc.unimode%v%"religion")); religion.pch[religion.pch>4] = 50

plot(sc.unimode, edge.lwd = "codecisions",
     vertex.col = 2*(-1*sc.unimode%v%"appointed"+4), 
     vertex.cex = sc.unimode%v%"appearances"/15,
     vertex.sides = religion.pch,
     edge.col = "gray",
     label = sc.unimode%v%"label",
     main = "Connections of Judges in 1st Amendment Decisions")

legend("topleft", legend = c("Dem. Appoint", "Rep. Appoint"), col = c(4,2), pch = 19, cex = 1)
legend("bottomleft", legend = levels(as.factor(sc.unimode%v%"religion")), col = 1, pch = c(17,18,19))

```

#### Why model? 

- We can use the visualization to learn some things about the network, but there's a limit on the number of things we can visualize at one time.

- Statnet has a few layout options, which can change how we see the network.

```{r layout modes, cache = T, eval = T, echo = F, fig.width = 8}

par(mfrow = c(1,3))
par(mai = rep(.2,4))

set.seed(1)

plot(sc.unimode, edge.lwd = "codecisions",
     vertex.col = 2*(-1*sc.unimode%v%"appointed"+4), 
     vertex.cex = sc.unimode%v%"appearances"/15,
     vertex.sides = religion.pch,
     edge.col = "gray",
     label = sc.unimode%v%"label",
     main = "Fruchterman Reingold",
     mode = "fruchtermanreingold")

plot(sc.unimode, edge.lwd = "codecisions",
     vertex.col = 2*(-1*sc.unimode%v%"appointed"+4), 
     vertex.cex = sc.unimode%v%"appearances"/15,
     vertex.sides = religion.pch,
     edge.col = "gray",
     label = sc.unimode%v%"label",
     main = "Circle layout",
     mode = "circle")

plot(sc.unimode, edge.lwd = "codecisions",
     vertex.col = 2*(-1*sc.unimode%v%"appointed"+4), 
     vertex.cex = sc.unimode%v%"appearances"/15,
     vertex.sides = religion.pch,
     edge.col = "gray",
     label = sc.unimode%v%"label",
     main = "Kamada-Kawai",
     mode = "kamadakawai")
```

- PLOTTING HAS RANDOMNESS. We use `set.seed` to fix a location, but note that randomness can impact interpretation.

- Note how centrality and politics (liberal vs. conservative) affect the layout.

- We want to analyze the effects of some factors while controlling for others.

- We'll use the unimodal network for modelling. It's small, gets at our questions of interest, and is relatively easy to interpret.

## B) Fit ERGM variations

```{r supreme_court_network_ergm, echo = T, cache = T, warning = F, message = F}

#?ergm.terms

sc.unimode%v%"birthyear" = sc.nodes$birthyear[1:n.judges]
sc.ergm = ergm(sc.unimode ~ edges + nodematch("gender") + nodematch("religion") +
                 nodematch("appointed") + nodecov("birthyear") + absdiff("birthyear") + 
                 nodefactor("role"))

summary(sc.ergm)

summary_formula(sc.unimode ~ density())

# What is the relationship between birth year and degree in the network?
# Not a super strong though noticeable at the tails
plot(sc.unimode%v%"birthyear", sc.unimode%v%"appearances")
```

A density of about 80% high is very high for a social network. In our current network, two judges are connected if they share any decision. This may be masking differences between them. Also our results our skewed by how much judges overlapped in their appointments.

Let's try normalizing and thinning the network using a percentage-wise cutoff for edges to be included. This is a common strategy, but we should apply it carefully because it affects our model. Ideally we would use a cutoff that is meaningful in context.

```{r supreme_court_network_thin_ergm, echo = T, cache = T, warning = F, message = F}

# try thinning

sc.projection.norm = sc.projection
diag(sc.projection.norm) = 0
sc.projection.norm = sc.projection.norm/rowSums(sc.projection.norm)
hist(sc.projection.norm, breaks = 40)
sc.projection.norm[sc.projection.norm < .1] = 0

sc.unimode.thin = network(sc.projection.norm, directed = F, vertex.attr = sc.attr.list)
sc.unimode.thin%v%"birthyear" = sc.nodes$birthyear[1:n.judges]

plot(sc.unimode.thin, 
     vertex.col = 2*(-1*sc.unimode%v%"appointed"+4), 
     vertex.cex = sc.unimode%v%"appearances"/15,
     #vertex.sides = religion.pch,
     edge.col = "gray",
     label = sc.unimode%v%"label",
     main = "Network of 1st Amendment Decisions")

sc.ergm.thin = ergm(sc.unimode.thin ~ edges + 
                      nodematch("gender") + 
                      nodematch("religion") +
                      nodematch("appointed") + 
                      nodecov("birthyear") +
                      absdiff("birthyear") + 
                      nodefactor("role")
                    )
summary(sc.ergm.thin)

sc.ergm.thin = ergm(sc.unimode.thin ~ edges + 
                      #nodematch("gender") + 
                      nodematch("religion") +
                      nodematch("appointed") + 
                      nodecov("birthyear") + 
                      absdiff("birthyear")
                      #nodefactor("role")
                    )

summary(sc.ergm.thin)
```

> "We do not have Obama judges or Trump judges, Bush judges or Clinton judges. What we have is an extraordinary group of dedicated judges doing their level best to do equal right to those appearing before them." -Chief Justice John Roberts (11-21-2018)

## C) Evaluate ERGM fit

How can we tell if the fit is good?

```{r supreme_court_network_ergm_gof, echo = T, cache = T, warning = F, message = F, fig.width = 8}

# Use gof
sc.ergm.thin.gof = gof(sc.ergm.thin)
plot(sc.ergm.thin.gof)

# Inspect simulations 
summary_formula(sc.unimode.thin ~ triangles()) #summary_formula replaced summary.statistics
summary_formula(simulate(sc.ergm.thin) ~ triangles())

# Compare simulated to true
par(mfrow = c(1,2))
par(mai = rep(.2, 4))

plot(sc.unimode.thin, 
     vertex.col = 2*(-1*sc.unimode%v%"appointed"+4), 
     vertex.cex = sc.unimode%v%"appearances"/15,
     #vertex.sides = religion.pch,
     edge.col = "gray",
     label = sc.unimode%v%"label",
     main = "Network of 1st Amendment Decisions", label.cex = .5)


plot(simulate(sc.ergm.thin), 
     vertex.col = 2*(-1*sc.unimode%v%"appointed"+4), 
     vertex.cex = sc.unimode%v%"appearances"/15,
     #vertex.sides = religion.pch,
     edge.col = "gray",
     label = sc.unimode%v%"label",
     main = "Simulation from model", label.cex = .5)


```

Why is this fitting so quickly?

```{r supreme_court_network_ergm_gw, echo = T, cache = T, warning = F, message = F}

# For MCMC
sc.ergm.thin.mle = ergm(sc.unimode.thin ~ edges + 
                      nodematch("religion") +
                      nodematch("appointed") + 
                      nodecov("birthyear") + 
                      absdiff("birthyear"),
                      estimate = "MLE", control = control.ergm("force.main" = TRUE))

plot(sc.ergm.thin.mle)
# same as mcmc.diagnostics(sc.ergm.thin.mle)

# Dependent terms always force MCMC
sc.ergm.thin.gw = ergm(sc.unimode.thin ~ edges + 
                      nodematch("religion") +
                      nodematch("appointed") + 
                      nodecov("birthyear") + 
                      absdiff("birthyear") +
                      #gwesp(.5, fixed = T) + 
                      gwdegree(.5, fixed = T)
                    )

summary(sc.ergm.thin.gw)
plot(sc.ergm.thin.gw)
sc.ergm.thin.gw.gof = gof(sc.ergm.thin.gw)
plot(sc.ergm.thin.gw.gof)


# Compare simulated to true
par(mfrow = c(1,2))

plot(sc.unimode.thin, 
     vertex.col = 2*(-1*sc.unimode%v%"appointed"+4), 
     vertex.cex = sc.unimode%v%"appearances"/15,
     #vertex.sides = religion.pch,
     edge.col = "gray",
     label = sc.unimode%v%"label",
     main = "Connections of Judges in 1st Amendment Decisions")


plot(simulate(sc.ergm.thin.gw), 
     vertex.col = 2*(-1*sc.unimode%v%"appointed"+4), 
     vertex.cex = sc.unimode%v%"appearances"/15,
     #vertex.sides = religion.pch,
     edge.col = "gray",
     label = sc.unimode%v%"label",
     main = "Simulation from model")
```

We could try to add a `triangles` term to the model formula but the fit will fail due to model degeneracy.
You'll see some kind of error message, e.g. "MCMLE estimation stuck. There may be excessive correlation between model terms, suggesting a poor model for the observed data."

```{r supreme_court_network_ergm_tri, eval = F, echo = T, cache = T}

sc.ergm.gw = ergm(sc.unimode.thin ~ edges + 
                      nodematch("religion") +
                      nodematch("appointed") + 
                      nodecov("birthyear") + 
                      absdiff("birthyear") +
                      triangles)

```

## D) Something to try

- Upload _ data and convert to a network
- Make a plot with vertices colored by _
- Fit an ergm with terms for _

------------------------------------------------------------------------------------------

# 4. Additional sofware:

## A) Interactive co-indicence network with `netCoin`.

```{r judges_netcoin, eval = T, echo = T, message = F, warning = F, cache = T}

library(netCoin)

sc.coin = coin(t(as.sociomatrix(sc.bipartite)))
tmp = asNodes(sc.coin); tmp$Label = sc.nodes$Label[1:n.judges]
sc.nodes = read.csv(paste(wd, "GSoCversionOpinions-NODES.csv", sep = ""))
sc.nodes = data.frame(cbind(name = as.character(sc.nodes$Label), sc.nodes))
sc.nodes.tmp = sc.nodes[1:n.judges,]
sc.nodes.tmp$name = 1:14 # a character vector didn't work REPORT!
sc.nodes.tmp$frequency = tmp$frequency

sc.allnet = allNet(incidences = t(as.sociomatrix(sc.bipartite)), nodes = sc.nodes.tmp)
plot(sc.allnet)
```

We're concerned that the number of overlapping cases between two justices is influencing their implied similarity.

We can pick a similarity metric that somewhat accounts for this. If neither judge is attached to a decision, it is because neither made that decision, or one or both were not on the bench at that time. We are not interested in the latter case, so we want to focus our attention on the number of times they decided in the same way, relative to the number of times they decided in the same or different ways. For this we can use the Kulczynski similarity metric @netCoin18.

$$\text{Kulczynski} = (\frac{a}{a+b} + \frac{a}{a+c})/2,$$

where $a, b, c, d$ describe co-occurence between two events as follows:

```{r similarity_table, echo = F, results = "asis", fig.width = 3, cache  = T, warnoing = F, message = F}

library(knitr)
library(kableExtra)

kable(data.frame(present = c("a","b"), absent = c("c","d"), row.names = c("present", "absent")), format = "html") %>%
  kableExtra::kable_styling(full_width = F) #%>% add_header_above(c(" ", "Event 2" = 2))
```


A complete analysis would normalize for the number of possible co-occurences of any two justices when calculating edge strength or similarity more generally.

```{r judges_netcoin2, eval = T, echo = T, message = F, warning = F, cache = T}

sc.allnet = allNet(incidences = t(as.sociomatrix(sc.bipartite)), nodes = sc.nodes.tmp, procedures = c("f", "i", "ii", "r", "k", "h"))
sc.allnet
round(cor(sc.allnet[["links"]][,c("frequencies", "sConditional", "tConditional", "Russell", "Kulczynski", "Haberman", "p(Z)")]), 2)
plot(sc.allnet)
```

We can use the dropdown to compare the various similarity/distance metrics and use the color and width to highlight the strength of relationships.

These are the other metrics in the drop-down. We let the diagonal of the adjacency matrix equal the number of apperances of each justice:

- frequencies = $A_jk$
- sConditional = $A_jk/A_jj$
- tConditional = $A_jk/A_kk$
- Russel is $\frac{a}{a+b+c+d}$

- Haberman is a standardized measure of how much the observed $A_jk$ exceeds what we could have expected if $j$ and $k$ were independent. P(Z) puts that value on a normal scale, where a lower probability suggests stronger dependence.

As expected, the Kulczynski metric can highlight relationships outside the nodes that occur most often. The Haberman metric, and with it the P(Z) can as well, refelcting their standardization.

## B) Dynamic visualizaiton with `networkDynamic` and `ndtv`
 
Illustrate the functionality of one of the dynamic visualization packages in combination with the `scholar` package.
 
```{r dynamic_vis_setup, eval = T, cache = T, warning = F, message = F}

library(stringr)
library(statnet)
library(scholar)
library(networkDynamic)
library(ndtv)
library(ergm)
library(igraph)
```

```{r dynamic_vis, echo = T, results = "hide", eval = T, cache = T, warning = F, message = F}

butts = get_publications("-VGAs1cAAAAJ&hl=en", cstart = 0, pagesize = 100, flush = T)

#limited in that only 6 or 7 authors show up
butts.coauthors = sapply(as.character(butts$author), strsplit, ", ")

#fixes
butts[which(butts$year==1861), "year"] = 2016

butts.coauthors = lapply(butts.coauthors, str_replace, pattern = "C Butts", replacement = "CT Butts")
butts.coauthors = lapply(butts.coauthors, str_replace, pattern = "MCT Butts", replacement = "CT Butts")
butts.coauthors = lapply(butts.coauthors, str_replace, pattern = "ZW Almquist", replacement = "Z Almquist")
butts.coauthors = lapply(butts.coauthors, str_replace, pattern = "SB de-Moll", replacement = "S  Bender-deMoll")
butts.coauthors = lapply(butts.coauthors, str_replace, pattern = "PN Krivitsky", replacement = "P Krivitsky")
butts.coauthors = lapply(butts.coauthors, str_replace, pattern = "DR Hunter", replacement = "D Hunter")
butts.coauthors = lapply(butts.coauthors, str_replace, pattern = "RM Acton", replacement = "R Acton")
butts.coauthors = lapply(butts.coauthors, str_replace, pattern = "S Mark", replacement = "MS Handcock")
butts.coauthors = lapply(butts.coauthors, function(x) x[x!="..."])

#make sure butts in all
butts.coauthors = sapply(butts.coauthors, function(x) {
  if (! ("CT Butts" %in% x)) {
    x = c(x,"CT Butts") 
  } else x = x})

# dealt with multiple butts'
#butts.coauthors.unique[str_detect(butts.coauthors.unique, "[w|W]illiams")]
butts.coauthors.unique = unique(unlist(butts.coauthors))
sort(butts.coauthors.unique)

# 1. Co-authors ####

#which.max(lapply(lapply(butts.coauthors, str_detect, "S butts Cowper"), sum))
butts.edges = lapply(butts.coauthors, function(x) {butts.coauthors.unique %in% x})

# number of single
butts.degree = sapply(butts.edges, sum); table(butts.degree)

N = length(butts.coauthors.unique)
P = length(butts.edges)
tmp = matrix(do.call(cbind, butts.edges), nrow = N, ncol = P)
rownames(tmp) = butts.coauthors.unique
butts.mat = tmp %*% t(tmp)

author.codegree = butts.mat["CT Butts",]
author.codegree2 = log(author.codegree) + .5

# 2. static net ####

#set.seed(3) there is randomness in the layouts
butts.net = as.network(butts.mat, directed = F, names.eval = "edge.lwd", ignore.eval = F)
butts.net%v%"author" = butts.coauthors.unique
butts.net%v%"vertex.cex" = author.codegree2 #how many papers with butts?
butts.net%v%"vertex.pid" = 1:length(butts.coauthors.unique) #how many papers with butts?

plot.network(butts.net, edge.col = "white", 
             label = "vertex.names", label.cex = .5,
             label.pad = 0, label.pos = 1,
             edge.lwd = butts.net%e%"edge.lwd")

butts.igraph = intergraph::asIgraph(butts.net)
butts.layout = data.frame(layout.fruchterman.reingold(butts.igraph))
colnames(butts.layout) = c("x","y")

# 3. dynamic net ####

table(butts$year)
slices = seq(1997,2018, by = 1)
start = min(slices); end = max(slices)
author.first = sapply(butts.coauthors.unique, #flexible depending on source google scholar or pamela
  function(x) {
   min(butts[which(sapply(butts.coauthors, function(y) {x %in% y})),"year"], na.rm = T)
  })

butts.network.list = lapply(slices, function(i) {
  authors.sub = author.first <= i
  butts.sort = subset(butts, butts$year <= i)
  N.sub = sum(authors.sub)
  P.sub = nrow(butts.sort)
  butts.edges.sub = lapply(butts.edges[butts$year <= i], function(x) x[authors.sub])
  tmp = matrix(do.call(cbind, butts.edges.sub), nrow = N.sub, ncol = P.sub)
  
  rownames(tmp) = butts.coauthors.unique[authors.sub]
  coauthor.mat = tmp %*% t(tmp)
  coauthor.net = as.network(coauthor.mat, directed = F, names.eval = "edge.lwd", ignore.eval = F)
  coauthor.net%v%"author" = butts.coauthors.unique[authors.sub]
  coauthor.net%v%"x" = butts.layout$x[authors.sub]
  coauthor.net%v%"y" = butts.layout$y[authors.sub]
  coauthor.net%v%"vertex.pid" = which(authors.sub)
  coauthor.net%v%"vertex.cex" = author.codegree2[authors.sub] #how many papers with butts?
  return(coauthor.net)
})

tmp = vector(mode = "list", length=min(slices)-1)
tmp = lapply(tmp, function(x) butts.network.list[[1]])
butts.network.list = c(tmp, butts.network.list)

butts.dynamic = networkDynamic(base.net=butts.net, network.list = butts.network.list,
                                  vertex.pid = "vertex.pid", create.TEAs = T)
butts.dynamic 

compute.animation(butts.dynamic, animation.mode = "useAttribute",
                  slice.par=list(start=start, end=end, interval=2, aggregate.dur = 2, rule='latest'),
                  weight.attr = c("edge.lwd"))

render.d3movie(butts.dynamic, usearrows = F, displaylabels = T,
               #col = "white", #fix in html
               label= "author",
               vertex.cex = "vertex.cex",
               vertex.tooltip=paste(butts.net%v%'author', sep = "<br>"),
               label.col = "white",
               label.cex = .8,
               vertex.col = "skyblue4",
               edge.col = "navy",
               edge.lwd = "edge.lwd",
               main = "Carter Butts Co-Author Network over Time: 1997-2018",
               xlab = "test",
               bg="black",
               vertex.border="#333333",
               render.par = list(show.time = TRUE, show.stats = "~edges"),
               #launchBrowser=F, filename="~/Documents/DSI/butts/buttsNet.html", 
               d3.options = list(slider = TRUE))

```

- fastnet

